{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0ciwsrZ9kD4"
   },
   "source": [
    "### Import Packages & Define Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "gcrGHA4OEcV1",
    "outputId": "6444b14d-1ef3-43b6-d854-9a9864f195f0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "POLcWrZZFWFS",
    "outputId": "9f1b3640-c441-4c5c-f0bd-3c8a70199f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLZlxL-jEZVW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDWWpzlPEZVk"
   },
   "outputs": [],
   "source": [
    "R_max = 5 # Maximum rating value possible\n",
    "M = 49289  # No. of users in Epinions Dataset\n",
    "N = 139738  # No. of items in Epinions Dataset\n",
    "D = 10 # Dimensionality of latent space for users and items\n",
    "lamda = 0.001 # Hyperparameter for loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TeCx2ilBEZVt"
   },
   "source": [
    "### Read Epinions Dataset into Ratings Matrix and Trust Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjZX0IBLEZVv"
   },
   "outputs": [],
   "source": [
    "ratings_file = \"drive/My Drive/IR_Project/data/epinions_ratings_data.txt\"\n",
    "trust_file = \"drive/My Drive/IR_Project/data/standardized_epinions_trust_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlZVlPvcEZV4"
   },
   "outputs": [],
   "source": [
    "# LEADS TO MEMORY ERROR\n",
    "# def read_ratings_data():\n",
    "#     global M, N, ratings_file\n",
    "#     ratings_matrix = np.zeros((M, N)) # 0 rating means USER HAS NOT RATED THE ITEM\n",
    "#     fr = open(ratings_file, 'r')\n",
    "#     for line in fr:\n",
    "#         fields = line.strip().split(' ')\n",
    "#         user_id = int(fields[0])\n",
    "#         item_id = int(fields[1])\n",
    "#         rating = float(fields[2])/R_max\n",
    "#         ratings_matrix[user_id-1, item_id-1] = rating\n",
    "#     fr.close()\n",
    "#     return ratings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOXPs7CgEZV-"
   },
   "outputs": [],
   "source": [
    "# LEADS TO MEMORY ERROR\n",
    "# ratings_matrix = read_ratings_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "puAgfMrWEZWH"
   },
   "outputs": [],
   "source": [
    "# LEADS TO MEMORY ERROR\n",
    "# def read_trust_data():\n",
    "#     global M, trust_file\n",
    "#     trust_matrix = np.zeros((M, M)) # 0 means TRUST DATA NOT AVAILABLE\n",
    "#     fr = open(trust_file, 'r')\n",
    "#     for line in fr:\n",
    "#         fields = line.strip().split(' ')\n",
    "#         user1_id = int(fields[0])\n",
    "#         user2_id = int(fields[1])\n",
    "#         trust_value = float(fields[2])\n",
    "#         trust_matrix[user1_id-1, user2_id-1] = trust_value\n",
    "#     fr.close()\n",
    "#     return trust_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pn98XfpBEZWN"
   },
   "outputs": [],
   "source": [
    "# LEADS TO MEMORY ERROR\n",
    "# trust_matrix = read_trust_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5z2rly9n3ptZ"
   },
   "outputs": [],
   "source": [
    "def read_ratings_data():\n",
    "    global ratings_file\n",
    "    ratings_data = pd.read_csv(ratings_file, sep=\" \", header=None)\n",
    "    ratings_data.columns = [\"user_id\", \"item_id\", \"rating\"]\n",
    "    return ratings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cELMhC7l4uqo"
   },
   "outputs": [],
   "source": [
    "ratings_data = read_ratings_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "3eposBwb7byz",
    "outputId": "5dbf7499-6627-4d01-dcf9-c81608dcaba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id      int64\n",
      "item_id      int64\n",
      "rating     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "ratings_data[\"rating\"] /= R_max\n",
    "convert_dict = {\"user_id\": int,\n",
    "                \"item_id\": int,\n",
    "                \"rating\": float}\n",
    "ratings_data = ratings_data.astype(convert_dict)\n",
    "print(ratings_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "eQpjOC-T4zc2",
    "outputId": "96f219d8-9a63-4877-9e7b-603322b015fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0        1      101     1.0\n",
       "1        1      102     0.6\n",
       "2        1       10     0.6\n",
       "3        1      103     1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "CT1-sHnU5eoY",
    "outputId": "d7924345-dfd5-4380-9ac9-2c003f9ac278"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>664819</th>\n",
       "      <td>49289</td>\n",
       "      <td>3862</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664820</th>\n",
       "      <td>49289</td>\n",
       "      <td>3939</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664821</th>\n",
       "      <td>49289</td>\n",
       "      <td>60213</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664822</th>\n",
       "      <td>49289</td>\n",
       "      <td>62722</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating\n",
       "664819    49289     3862     0.8\n",
       "664820    49289     3939     1.0\n",
       "664821    49289    60213     0.8\n",
       "664822    49289    62722     0.8"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGAgFvS062E9"
   },
   "outputs": [],
   "source": [
    "def read_trust_data():\n",
    "    global trust_file\n",
    "    trust_data = pd.read_csv(trust_file, sep=\" \", header=None)\n",
    "    trust_data.columns = [\"user1_id\", \"user2_id\", \"trust_val\"]\n",
    "    return trust_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Sz1INY87tBO"
   },
   "outputs": [],
   "source": [
    "trust_data = read_trust_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "xBsIwAw47Qlb",
    "outputId": "72e1c539-c6ce-48ff-a367-187645efb950"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user1_id</th>\n",
       "      <th>user2_id</th>\n",
       "      <th>trust_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22605</td>\n",
       "      <td>42915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22605</td>\n",
       "      <td>5052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22605</td>\n",
       "      <td>42913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22605</td>\n",
       "      <td>18420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user1_id  user2_id  trust_val\n",
       "0     22605     42915          1\n",
       "1     22605      5052          1\n",
       "2     22605     42913          1\n",
       "3     22605     18420          1"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trust_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "47RLJVaQ7V3Z",
    "outputId": "8a61b8a5-2aad-437e-bfc7-c8486dc629d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user1_id</th>\n",
       "      <th>user2_id</th>\n",
       "      <th>trust_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487179</th>\n",
       "      <td>36960</td>\n",
       "      <td>1056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487180</th>\n",
       "      <td>36960</td>\n",
       "      <td>422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487181</th>\n",
       "      <td>36960</td>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487182</th>\n",
       "      <td>36960</td>\n",
       "      <td>12784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user1_id  user2_id  trust_val\n",
       "487179     36960      1056          1\n",
       "487180     36960       422          1\n",
       "487181     36960       804          1\n",
       "487182     36960     12784          1"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trust_data.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hGRaVso7lNcm"
   },
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.80 # Ratio of training to validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSwyEAPDjuBT"
   },
   "outputs": [],
   "source": [
    "ratings_data_train, ratings_data_test = train_test_split(ratings_data, train_size=TRAIN_RATIO, shuffle=True, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "X6PSgGpBlZ0y",
    "outputId": "d619ecd0-db40-4dd2-d784-ab2855b33cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531858\n",
      "132965\n"
     ]
    }
   ],
   "source": [
    "print(len(ratings_data_train))\n",
    "print(len(ratings_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "l4uqyFJFoWJz",
    "outputId": "feb0ec5d-33d9-4204-80b5-68a8aec1278b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94467</th>\n",
       "      <td>804</td>\n",
       "      <td>56181</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>11</td>\n",
       "      <td>824</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382104</th>\n",
       "      <td>9866</td>\n",
       "      <td>43033</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584599</th>\n",
       "      <td>29534</td>\n",
       "      <td>94653</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449167</th>\n",
       "      <td>14368</td>\n",
       "      <td>9393</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating\n",
       "94467       804    56181     0.8\n",
       "828          11      824     1.0\n",
       "382104     9866    43033     1.0\n",
       "584599    29534    94653     1.0\n",
       "449167    14368     9393     1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "3LxDeOchocuj",
    "outputId": "beb22892-6178-4fb5-b51e-eb03ddc5dc39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480168</th>\n",
       "      <td>16803</td>\n",
       "      <td>126965</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623970</th>\n",
       "      <td>37756</td>\n",
       "      <td>2422</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82677</th>\n",
       "      <td>715</td>\n",
       "      <td>2956</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207470</th>\n",
       "      <td>2730</td>\n",
       "      <td>49213</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521821</th>\n",
       "      <td>21081</td>\n",
       "      <td>130213</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating\n",
       "480168    16803   126965     1.0\n",
       "623970    37756     2422     0.8\n",
       "82677       715     2956     0.8\n",
       "207470     2730    49213     0.8\n",
       "521821    21081   130213     0.8"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data_train.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "0zJGUIQ7ocrU",
    "outputId": "a9d98e72-ad57-42e8-bcb6-31742f5d1643"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66340</th>\n",
       "      <td>501</td>\n",
       "      <td>6864</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46401</th>\n",
       "      <td>375</td>\n",
       "      <td>1072</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102744</th>\n",
       "      <td>953</td>\n",
       "      <td>59912</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207332</th>\n",
       "      <td>2727</td>\n",
       "      <td>52999</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429791</th>\n",
       "      <td>12926</td>\n",
       "      <td>2750</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating\n",
       "66340       501     6864     1.0\n",
       "46401       375     1072     0.6\n",
       "102744      953    59912     1.0\n",
       "207332     2727    52999     1.0\n",
       "429791    12926     2750     0.8"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "eyUIiXqVocnV",
    "outputId": "bb763a75-5525-4bf0-f16e-47cdec04030e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360986</th>\n",
       "      <td>8740</td>\n",
       "      <td>88696</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500537</th>\n",
       "      <td>18774</td>\n",
       "      <td>8533</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592152</th>\n",
       "      <td>30754</td>\n",
       "      <td>61116</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385853</th>\n",
       "      <td>10057</td>\n",
       "      <td>96342</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622059</th>\n",
       "      <td>37355</td>\n",
       "      <td>58284</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating\n",
       "360986     8740    88696     0.8\n",
       "500537    18774     8533     1.0\n",
       "592152    30754    61116     1.0\n",
       "385853    10057    96342     0.8\n",
       "622059    37355    58284     0.8"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data_test.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bSnSeuNM3hOe"
   },
   "source": [
    "### Train Truster Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJnlS5rw3gt4"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42) # Set any random seed for reproducibility\n",
    "# Browse Reviews Behaviour Matrix (Influence from other users)- Approximates User feature matrix U in Truster Model\n",
    "B_trusterMF = Variable(torch.empty((D, M)).normal_(mean=0.0, std=0.1), requires_grad=True) \n",
    "# Item feature matrix\n",
    "V_trusterMF = Variable(torch.empty((D, N)).normal_(mean=0.0, std=0.1), requires_grad=True) \n",
    "# Write Reviews Behaviour Matrix (Influence other users)\n",
    "W_trusterMF = Variable(torch.empty((D, M)).normal_(mean=0.0, std=0.1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lmEGHgs-BL9r"
   },
   "outputs": [],
   "source": [
    "# nbi - no. of ratings given by user i\n",
    "# nvj - no. of ratings given to item j\n",
    "def calculate_nbi_and_nvj():\n",
    "    global ratings_data_train, M, N\n",
    "    nbi = np.zeros(M)\n",
    "    nvj = np.zeros(N)\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        nbi[int(ratings_data_train.iloc[idx][\"user_id\"])-1] += 1\n",
    "        nvj[int(ratings_data_train.iloc[idx][\"item_id\"])-1] += 1\n",
    "    return nbi, nvj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ctph6ZLEBL6W"
   },
   "outputs": [],
   "source": [
    "# mbi - no. of users who are trusted by user i\n",
    "# mwk - no. of users who trust user k\n",
    "def calculate_mbi_and_mwk():\n",
    "    global trust_data, M\n",
    "    mbi = np.zeros(M)\n",
    "    mwk = np.zeros(M)\n",
    "    for idx in range(len(trust_data)):\n",
    "        mbi[trust_data.iloc[idx][\"user1_id\"]-1] += 1\n",
    "        mwk[trust_data.iloc[idx][\"user2_id\"]-1] += 1\n",
    "    return mbi, mwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hRS2iRW-K_Fz",
    "outputId": "35fed102-29f9-44c0-c886-d862abb7badc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239.83849430084229  seconds\n"
     ]
    }
   ],
   "source": [
    "# start = time.time()\n",
    "# nbi, nvj = calculate_nbi_and_nvj()\n",
    "# end = time.time()\n",
    "# print(end-start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NowyF5LlNfAh"
   },
   "outputs": [],
   "source": [
    "# np.save('drive/My Drive/IR_Project/npy_files/nbi.npy', nbi)\n",
    "# # nbi = np.load('drive/My Drive/IR_Project/npy_files/nbi.npy')\n",
    "# np.save('drive/My Drive/IR_Project/npy_files/nvj.npy', nvj)\n",
    "# # nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a1MXERniBL0n",
    "outputId": "792c5b12-7840-48a0-fc73-64b109509fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190.73650598526  seconds\n"
     ]
    }
   ],
   "source": [
    "# start = time.time()\n",
    "# mbi, mwk = calculate_mbi_and_mwk()\n",
    "# end = time.time()\n",
    "# print(end-start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBE9hfQSPrBO"
   },
   "outputs": [],
   "source": [
    "# np.save('drive/My Drive/IR_Project/npy_files/mbi.npy', mbi)\n",
    "# # mbi = np.load('drive/My Drive/IR_Project/npy_files/mbi.npy')\n",
    "# np.save('drive/My Drive/IR_Project/npy_files/mwk.npy', mwk)\n",
    "# # mwk = np.load('drive/My Drive/IR_Project/npy_files/mwk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rLSFHuUZXgGs"
   },
   "outputs": [],
   "source": [
    "# nbi - no. of ratings given by user i\n",
    "nbi = np.load('drive/My Drive/IR_Project/npy_files/nbi.npy')\n",
    "# nvj - no. of ratings given to item j\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "# mbi - no. of users who are trusted by user i\n",
    "mbi = np.load('drive/My Drive/IR_Project/npy_files/mbi.npy')\n",
    "# mwk - no. of users who trust user k\n",
    "mwk = np.load('drive/My Drive/IR_Project/npy_files/mwk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHlxdNfFfFfj"
   },
   "outputs": [],
   "source": [
    "epochs = 2 # No. of epochs\n",
    "alpha_lr = 0.005 # Learning rate\n",
    "optimizer = optim.SGD([B_trusterMF, V_trusterMF, W_trusterMF], lr=alpha_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "DD85XvC5fFUL",
    "outputId": "251d9cd2-ff70-4c5c-a8b0-f714a336ee52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 , loss:  tensor(200327.6875, grad_fn=<AddBackward0>) , time(seconds):  4071.5971846580505\n",
      "Iteration:  1 , loss:  tensor(200275.1406, grad_fn=<AddBackward0>) , time(seconds):  4102.508572340012\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-503d548a9fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrust_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0muser1_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrust_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user1_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0muser2_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrust_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user2_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtrust_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrust_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trust_val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB_trusterMF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser1_id\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_trusterMF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser2_id\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrust_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2157\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m     \u001b[0;31m# raise_missing is included for compat with the parent class signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_loc\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2938\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2940\u001b[0;31m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2941\u001b[0m             )\n\u001b[1;32m   2942\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# we will try to copy be-definition here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;31m# that we can convert the data to the requested dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_integer_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_cast_to_integer_array\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         )\n\u001b[1;32m   1359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcasted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36marray_equal\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36marray_equal\u001b[0;34m(a1, a2)\u001b[0m\n\u001b[1;32m   2337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(0, 0+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (4) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusterMF, \"drive/My Drive/IR_Project/B_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusterMF, \"drive/My Drive/IR_Project/V_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusterMF, \"drive/My Drive/IR_Project/W_trusterMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "23WCy80z-ciR"
   },
   "outputs": [],
   "source": [
    "B_trusterMF = Variable(torch.load(\"drive/My Drive/IR_Project/B_trusterMF_\"+str(1)+\".pth\"), requires_grad=True)\n",
    "V_trusterMF = Variable(torch.load(\"drive/My Drive/IR_Project/V_trusterMF_\"+str(1)+\".pth\"), requires_grad=True)\n",
    "W_trusterMF = Variable(torch.load(\"drive/My Drive/IR_Project/W_trusterMF_\"+str(1)+\".pth\"), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9TBDbWVRFgk"
   },
   "outputs": [],
   "source": [
    "nbi = np.load('drive/My Drive/IR_Project/npy_files/nbi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mbi = np.load('drive/My Drive/IR_Project/npy_files/mbi.npy')\n",
    "mwk = np.load('drive/My Drive/IR_Project/npy_files/mwk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxBGQuzJRyI1"
   },
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "alpha_lr = 0.4\n",
    "optimizer = optim.SGD([B_trusterMF, V_trusterMF, W_trusterMF], lr=alpha_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "cWoljsE9TnmO",
    "outputId": "f07bf50c-fb02-4041-ed85-9f75e901753c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2 , loss:  tensor(200225.3594, grad_fn=<AddBackward0>) , time(seconds):  4074.1277873516083\n",
      "Iteration:  3 , loss:  tensor(196336.4844, grad_fn=<AddBackward0>) , time(seconds):  4081.672408103943\n",
      "Iteration:  4 , loss:  tensor(153223.7031, grad_fn=<AddBackward0>) , time(seconds):  4115.792732000351\n",
      "Iteration:  5 , loss:  tensor(106160.9062, grad_fn=<AddBackward0>) , time(seconds):  4098.311906814575\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(2, 2+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (4) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusterMF, \"drive/My Drive/IR_Project/B_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusterMF, \"drive/My Drive/IR_Project/V_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusterMF, \"drive/My Drive/IR_Project/W_trusterMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-S2RbaCt-EO"
   },
   "outputs": [],
   "source": [
    "B_trusterMF = Variable(torch.load(\"drive/My Drive/IR_Project/B_trusterMF_\"+str(5)+\".pth\"), requires_grad=True)\n",
    "V_trusterMF = Variable(torch.load(\"drive/My Drive/IR_Project/V_trusterMF_\"+str(5)+\".pth\"), requires_grad=True)\n",
    "W_trusterMF = Variable(torch.load(\"drive/My Drive/IR_Project/W_trusterMF_\"+str(5)+\".pth\"), requires_grad=True)\n",
    "nbi = np.load('drive/My Drive/IR_Project/npy_files/nbi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mbi = np.load('drive/My Drive/IR_Project/npy_files/mbi.npy')\n",
    "mwk = np.load('drive/My Drive/IR_Project/npy_files/mwk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJdhJWXQt-BF"
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "alpha_lr = 0.4\n",
    "optimizer = optim.SGD([B_trusterMF, V_trusterMF, W_trusterMF], lr=alpha_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "IWpMKzQXt992",
    "outputId": "48f58483-f716-45b3-8ee1-bba0818cc723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  6 , loss:  tensor(137264.4062, grad_fn=<AddBackward0>) , time(seconds):  4790.483388185501\n",
      "Iteration:  7 , loss:  tensor(89258.1094, grad_fn=<AddBackward0>) , time(seconds):  4229.941075563431\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(6, 6+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (4) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusterMF, \"drive/My Drive/IR_Project/B_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusterMF, \"drive/My Drive/IR_Project/V_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusterMF, \"drive/My Drive/IR_Project/W_trusterMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lcks9n-lt95t"
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "alpha_lr = 0.25\n",
    "optimizer = optim.SGD([B_trusterMF, V_trusterMF, W_trusterMF], lr=alpha_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "__FtTqhvSsi5",
    "outputId": "511cf359-a279-4aec-a80b-a9a61ba7bf84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  8 , loss:  tensor(150490.4844, grad_fn=<AddBackward0>) , time(seconds):  4272.635210514069\n",
      "Iteration:  9 , loss:  tensor(77514.4375, grad_fn=<AddBackward0>) , time(seconds):  4330.430537939072\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(8, 8+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (4) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusterMF, \"drive/My Drive/IR_Project/B_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusterMF, \"drive/My Drive/IR_Project/V_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusterMF, \"drive/My Drive/IR_Project/W_trusterMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMqvJI-4S4Xg"
   },
   "outputs": [],
   "source": [
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "-dENfL8q0l9_",
    "outputId": "4699d18f-a154-405c-d2a0-29b1a5e53ad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  10 , loss:  tensor(56805.3047, grad_fn=<AddBackward0>) , time(seconds):  4252.879674196243\n",
      "Iteration:  11 , loss:  tensor(47447.3828, grad_fn=<AddBackward0>) , time(seconds):  4283.094748258591\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10, 10+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (4) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusterMF, \"drive/My Drive/IR_Project/B_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusterMF, \"drive/My Drive/IR_Project/V_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusterMF, \"drive/My Drive/IR_Project/W_trusterMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezc845IG1JrM"
   },
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), \"drive/My Drive/IR_Project/optimizer_trusterMF_11.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04OQBM0u0qx6"
   },
   "outputs": [],
   "source": [
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "HqP7BxUQVyPd",
    "outputId": "64cc3e6e-b0c1-42f1-df87-04b05584e6eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  12 , loss:  tensor(78582.5234, grad_fn=<AddBackward0>) , time(seconds):  4240.109281539917\n",
      "Iteration:  13 , loss:  tensor(42432.4609, grad_fn=<AddBackward0>) , time(seconds):  4237.006747484207\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(12, 12+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (4) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusterMF, \"drive/My Drive/IR_Project/B_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusterMF, \"drive/My Drive/IR_Project/V_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusterMF, \"drive/My Drive/IR_Project/W_trusterMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31CzsFu3WgKQ"
   },
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), \"drive/My Drive/IR_Project/optimizer_trusterMF_13.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zEpj10OM36q-"
   },
   "outputs": [],
   "source": [
    "nbi = np.load('drive/My Drive/IR_Project/npy_files/nbi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mbi = np.load('drive/My Drive/IR_Project/npy_files/mbi.npy')\n",
    "mwk = np.load('drive/My Drive/IR_Project/npy_files/mwk.npy')\n",
    "B_trusterMF = Variable(torch.load(\"drive/My Drive/IR_Project/B_trusterMF_\"+str(13)+\".pth\"), requires_grad=True)\n",
    "V_trusterMF = Variable(torch.load(\"drive/My Drive/IR_Project/V_trusterMF_\"+str(13)+\".pth\"), requires_grad=True)\n",
    "W_trusterMF = Variable(torch.load(\"drive/My Drive/IR_Project/W_trusterMF_\"+str(13)+\".pth\"), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "se5QALzlV7sc",
    "outputId": "102cebc7-9a93-4180-ca60-1932c6e95f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.25, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139718035755296, 139718035711896, 139718035712112]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.2, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139718035755296, 139718035711896, 139718035712112]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "alpha_lr = 0.20\n",
    "optimizer = optim.SGD([B_trusterMF, V_trusterMF, W_trusterMF], lr=alpha_lr)\n",
    "checkpt = torch.load(\"drive/My Drive/IR_Project/optimizer_trusterMF_13.pth\")\n",
    "optimizer.load_state_dict(checkpt)\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Tfk2PsbR29By",
    "outputId": "ea7d06f8-d29d-439a-9d4b-a33379afd772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  14 , loss:  tensor(52122.6172, grad_fn=<AddBackward0>) , time(seconds):  4210.962449550629\n",
      "Iteration:  15 , loss:  tensor(47897.1992, grad_fn=<AddBackward0>) , time(seconds):  4222.90231347084\n",
      "Iteration:  16 , loss:  tensor(254963.1562, grad_fn=<AddBackward0>) , time(seconds):  3934.3916993141174\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(14, 14+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (4) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusterMF, \"drive/My Drive/IR_Project/B_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusterMF, \"drive/My Drive/IR_Project/V_trusterMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusterMF, \"drive/My Drive/IR_Project/W_trusterMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4-3N99M23s_"
   },
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), \"drive/My Drive/IR_Project/optimizer_trusterMF_16.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQLLiRFf3ksm"
   },
   "source": [
    "### Train Trustee Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xcwYsycK3mdZ"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42) # Set any random seed for reproducibility\n",
    "# Browse Reviews Behaviour Matrix (Influence from other users)\n",
    "B_trusteeMF = Variable(torch.empty((D, M)).normal_(mean=0.0, std=0.1), requires_grad=True)\n",
    "# Item feature matrix\n",
    "V_trusteeMF = Variable(torch.empty((D, N)).normal_(mean=0.0, std=0.1), requires_grad=True)\n",
    "# Write Reviews Behaviour Matrix (Influence other users) - Approximates User feature matrix U in Trustee Model\n",
    "W_trusteeMF = Variable(torch.empty((D, M)).normal_(mean=0.0, std=0.1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RgZ48XhvrUQP"
   },
   "outputs": [],
   "source": [
    "# nwi - no. of ratings given by user i\n",
    "# nvj - no. of ratings given to item j\n",
    "def calculate_nwi_and_nvj():\n",
    "    global ratings_data_train, M, N\n",
    "    nwi = np.zeros(M)\n",
    "    nvj = np.zeros(N)\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        nwi[int(ratings_data_train.iloc[idx][\"user_id\"])-1] += 1\n",
    "        nvj[int(ratings_data_train.iloc[idx][\"item_id\"])-1] += 1\n",
    "    return nwi, nvj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMsiE4xNrUDk"
   },
   "outputs": [],
   "source": [
    "# mbk - no. of users who are trusted by user k\n",
    "# mwi - no. of users who trust user i\n",
    "def calculate_mwi_and_mbk():\n",
    "    global trust_data, M\n",
    "    mwi = np.zeros(M)\n",
    "    mbk = np.zeros(M)\n",
    "    for idx in range(len(trust_data)):\n",
    "        mwi[trust_data.iloc[idx][\"user2_id\"]-1] += 1\n",
    "        mbk[trust_data.iloc[idx][\"user1_id\"]-1] += 1\n",
    "    return mwi, mbk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HBd56rxyrT3j",
    "outputId": "651408e8-4bff-465a-bb9a-936ebf31bfda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217.5763931274414  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "nwi, nvj = calculate_nwi_and_nvj()\n",
    "end = time.time()\n",
    "print(end-start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7YjOLUyprT1l"
   },
   "outputs": [],
   "source": [
    "np.save('drive/My Drive/IR_Project/npy_files/nwi.npy', nwi)\n",
    "# nwi = np.load('drive/My Drive/IR_Project/npy_files/nwi.npy')\n",
    "np.save('drive/My Drive/IR_Project/npy_files/nvj.npy', nvj)\n",
    "# nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lBnieLuHrTwz",
    "outputId": "2dc6f334-cf6e-430c-e39b-907b44ae0d8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169.64254450798035  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mwi, mbk = calculate_mwi_and_mbk()\n",
    "end = time.time()\n",
    "print(end-start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UUxnTHLGQHgL"
   },
   "outputs": [],
   "source": [
    "np.save('drive/My Drive/IR_Project/npy_files/mwi.npy', mwi)\n",
    "# mwi = np.load('drive/My Drive/IR_Project/npy_files/mwi.npy')\n",
    "np.save('drive/My Drive/IR_Project/npy_files/mbk.npy', mbk)\n",
    "# mbk = np.load('drive/My Drive/IR_Project/npy_files/mbk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdqhd-EyQHXT"
   },
   "outputs": [],
   "source": [
    "epochs = 6 # No. of epochs\n",
    "alpha_lr = 0.4 # Learning Rate\n",
    "optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "ot3SwzbGQw3S",
    "outputId": "6d13c55e-ce35-445f-d80a-fcd3a806f02d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 , loss:  tensor(200326.6094, grad_fn=<AddBackward0>) , time(seconds):  4612.682894945145\n",
      "Iteration:  1 , loss:  tensor(197478.9688, grad_fn=<AddBackward0>) , time(seconds):  4287.265371084213\n",
      "Iteration:  2 , loss:  tensor(182978.7344, grad_fn=<AddBackward0>) , time(seconds):  4269.239253282547\n",
      "Iteration:  3 , loss:  tensor(263635.2500, grad_fn=<AddBackward0>) , time(seconds):  4309.928425550461\n",
      "Iteration:  4 , loss:  tensor(258949.3750, grad_fn=<AddBackward0>) , time(seconds):  4141.440163135529\n",
      "Iteration:  5 , loss:  tensor(140663.6094, grad_fn=<AddBackward0>) , time(seconds):  4089.9009263515472\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(0, 0+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (5) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusteeMF, \"drive/My Drive/IR_Project/B_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusteeMF, \"drive/My Drive/IR_Project/V_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusteeMF, \"drive/My Drive/IR_Project/W_trusteeMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ft-7Hu6Q5_x_"
   },
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), \"drive/My Drive/IR_Project/optimizer_trusteeMF_5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XX_Gk_bgdPF"
   },
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "alpha_lr = 0.25\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Rwq4YDT_gdKF",
    "outputId": "cd66af65-b954-44d2-8292-91bfab6385f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  6 , loss:  tensor(268725.0938, grad_fn=<AddBackward0>) , time(seconds):  4073.85556101799\n",
      "Iteration:  7 , loss:  tensor(164052.6562, grad_fn=<AddBackward0>) , time(seconds):  4068.013741016388\n",
      "Iteration:  8 , loss:  tensor(117212.2188, grad_fn=<AddBackward0>) , time(seconds):  4069.180951356888\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(6, 6+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (5) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusteeMF, \"drive/My Drive/IR_Project/B_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusteeMF, \"drive/My Drive/IR_Project/V_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusteeMF, \"drive/My Drive/IR_Project/W_trusteeMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wlza9suRQwrK"
   },
   "outputs": [],
   "source": [
    "B_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/B_trusteeMF_\"+str(8)+\".pth\"), requires_grad=True)\n",
    "V_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/V_trusteeMF_\"+str(8)+\".pth\"), requires_grad=True)\n",
    "W_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/W_trusteeMF_\"+str(8)+\".pth\"), requires_grad=True)\n",
    "nwi = np.load('drive/My Drive/IR_Project/npy_files/nwi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mwi = np.load('drive/My Drive/IR_Project/npy_files/mwi.npy')\n",
    "mbk = np.load('drive/My Drive/IR_Project/npy_files/mbk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "BEm9VGRXmb-a",
    "outputId": "3d5e829f-7d17-4ef0-a647-f3894c0e36fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.4, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140037430628216, 140037464580032, 140037430669816]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.2, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140037430628216, 140037464580032, 140037430669816]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "alpha_lr = 0.20\n",
    "optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)\n",
    "checkpt = torch.load(\"drive/My Drive/IR_Project/optimizer_trusteeMF_5.pth\")\n",
    "optimizer.load_state_dict(checkpt)\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "zJ6bj3YEmb4f",
    "outputId": "918cd3e9-0c35-403b-fe0f-afe0c97dc173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  9 , loss:  tensor(81233.1875, grad_fn=<AddBackward0>) , time(seconds):  3971.718724489212\n",
      "Iteration:  10 , loss:  tensor(67049.2891, grad_fn=<AddBackward0>) , time(seconds):  4145.7169761657715\n",
      "Iteration:  11 , loss:  tensor(158793.0312, grad_fn=<AddBackward0>) , time(seconds):  4074.2037785053253\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(9, 9+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (5) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusteeMF, \"drive/My Drive/IR_Project/B_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusteeMF, \"drive/My Drive/IR_Project/V_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusteeMF, \"drive/My Drive/IR_Project/W_trusteeMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-fk-QSRmbxy"
   },
   "outputs": [],
   "source": [
    "B_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/B_trusteeMF_\"+str(10)+\".pth\"), requires_grad=True)\n",
    "V_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/V_trusteeMF_\"+str(10)+\".pth\"), requires_grad=True)\n",
    "W_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/W_trusteeMF_\"+str(10)+\".pth\"), requires_grad=True)\n",
    "nwi = np.load('drive/My Drive/IR_Project/npy_files/nwi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mwi = np.load('drive/My Drive/IR_Project/npy_files/mwi.npy')\n",
    "mbk = np.load('drive/My Drive/IR_Project/npy_files/mbk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "KZvRDWTaGEvc",
    "outputId": "2973849f-474e-430f-987f-c459aa2ad44b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.4, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139984608295456, 139984608296752, 139984608295384]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139984608295456, 139984608296752, 139984608295384]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "alpha_lr = 0.10\n",
    "optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)\n",
    "checkpt = torch.load(\"drive/My Drive/IR_Project/optimizer_trusteeMF_5.pth\")\n",
    "optimizer.load_state_dict(checkpt)\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "BF1sGXbLGEsC",
    "outputId": "edcbbe73-341b-463f-a4bd-6040a0bc4620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  11 , loss:  tensor(158793.0312, grad_fn=<AddBackward0>) , time(seconds):  3878.8655200004578\n",
      "Iteration:  12 , loss:  tensor(96774.0391, grad_fn=<AddBackward0>) , time(seconds):  3938.159417629242\n",
      "Iteration:  13 , loss:  tensor(68495.6094, grad_fn=<AddBackward0>) , time(seconds):  3906.793427467346\n",
      "Iteration:  14 , loss:  tensor(56088.2305, grad_fn=<AddBackward0>) , time(seconds):  3914.5910284519196\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(11, 11+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (5) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusteeMF, \"drive/My Drive/IR_Project/B_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusteeMF, \"drive/My Drive/IR_Project/V_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusteeMF, \"drive/My Drive/IR_Project/W_trusteeMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJUE2wsNGEok"
   },
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), \"drive/My Drive/IR_Project/optimizer_trusteeMF_14.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CP2b5QfJGEkz"
   },
   "outputs": [],
   "source": [
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "cp04C71VI97k",
    "outputId": "eb059a02-5abd-4a21-f60d-f721ef80b294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  15 , loss:  tensor(49085.2188, grad_fn=<AddBackward0>) , time(seconds):  3943.584791660309\n",
      "Iteration:  16 , loss:  tensor(45018.8789, grad_fn=<AddBackward0>) , time(seconds):  3860.2556190490723\n",
      "Iteration:  17 , loss:  tensor(42387.2109, grad_fn=<AddBackward0>) , time(seconds):  3899.5941994190216\n",
      "Iteration:  18 , loss:  tensor(41521.9141, grad_fn=<AddBackward0>) , time(seconds):  4006.6741077899933\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(15, 15+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (5) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusteeMF, \"drive/My Drive/IR_Project/B_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusteeMF, \"drive/My Drive/IR_Project/V_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusteeMF, \"drive/My Drive/IR_Project/W_trusteeMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuQDUO72I932"
   },
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), \"drive/My Drive/IR_Project/optimizer_trusteeMF_18.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RwIw6N3FI9zH"
   },
   "outputs": [],
   "source": [
    "B_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/B_trusteeMF_\"+str(18)+\".pth\"), requires_grad=True)\n",
    "V_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/V_trusteeMF_\"+str(18)+\".pth\"), requires_grad=True)\n",
    "W_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/W_trusteeMF_\"+str(18)+\".pth\"), requires_grad=True)\n",
    "nwi = np.load('drive/My Drive/IR_Project/npy_files/nwi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mwi = np.load('drive/My Drive/IR_Project/npy_files/mwi.npy')\n",
    "mbk = np.load('drive/My Drive/IR_Project/npy_files/mbk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "pHqyh3hGG6qv",
    "outputId": "9d12ae59-eb21-4aa4-de2b-6d522aa1468c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140029422903016, 140029422903160, 140029456924392]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.04, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140029422903016, 140029422903160, 140029456924392]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "alpha_lr = 0.04\n",
    "optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)\n",
    "checkpt = torch.load(\"drive/My Drive/IR_Project/optimizer_trusteeMF_18.pth\")\n",
    "optimizer.load_state_dict(checkpt)\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "4Ab8fiLEG6nX",
    "outputId": "0956d6bd-45e9-42c3-f4a7-8844084ce105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  19 , loss:  tensor(39452.3984, grad_fn=<AddBackward0>) , time(seconds):  3930.1239247322083\n",
      "Iteration:  20 , loss:  tensor(38276.7695, grad_fn=<AddBackward0>) , time(seconds):  3961.7645902633667\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(19, 19+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (5) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusteeMF, \"drive/My Drive/IR_Project/B_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusteeMF, \"drive/My Drive/IR_Project/V_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusteeMF, \"drive/My Drive/IR_Project/W_trusteeMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feMvwiD-JTqw"
   },
   "outputs": [],
   "source": [
    "B_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/B_trusteeMF_\"+str(20)+\".pth\"), requires_grad=True)\n",
    "V_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/V_trusteeMF_\"+str(20)+\".pth\"), requires_grad=True)\n",
    "W_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/W_trusteeMF_\"+str(20)+\".pth\"), requires_grad=True)\n",
    "nwi = np.load('drive/My Drive/IR_Project/npy_files/nwi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mwi = np.load('drive/My Drive/IR_Project/npy_files/mwi.npy')\n",
    "mbk = np.load('drive/My Drive/IR_Project/npy_files/mbk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "S524D77jwUSc",
    "outputId": "f7cae860-5683-4465-927c-5cfeedf0bf4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140597119802032, 140597119824808, 140597119825168]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.08, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140597119802032, 140597119824808, 140597119825168]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "alpha_lr = 0.08\n",
    "optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)\n",
    "checkpt = torch.load(\"drive/My Drive/IR_Project/optimizer_trusteeMF_18.pth\")\n",
    "optimizer.load_state_dict(checkpt)\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "WKsAPVjcwULe",
    "outputId": "29f6cba8-5d7d-4adb-a7df-f7b7d8712cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  21 , loss:  tensor(37322.4219, grad_fn=<AddBackward0>) , time(seconds):  4213.098088264465\n",
      "Iteration:  22 , loss:  tensor(35904.5938, grad_fn=<AddBackward0>) , time(seconds):  4264.500135183334\n",
      "Iteration:  23 , loss:  tensor(35893.6641, grad_fn=<AddBackward0>) , time(seconds):  4189.6291427612305\n",
      "Iteration:  24 , loss:  tensor(34901.6406, grad_fn=<AddBackward0>) , time(seconds):  4171.842748403549\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(21, 21+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (5) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusteeMF, \"drive/My Drive/IR_Project/B_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusteeMF, \"drive/My Drive/IR_Project/V_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusteeMF, \"drive/My Drive/IR_Project/W_trusteeMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDRmtY8OwUCu"
   },
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), \"drive/My Drive/IR_Project/optimizer_trusteeMF_24.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sLwGLoSexPLp"
   },
   "outputs": [],
   "source": [
    "B_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/B_trusteeMF_\"+str(24)+\".pth\"), requires_grad=True)\n",
    "V_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/V_trusteeMF_\"+str(24)+\".pth\"), requires_grad=True)\n",
    "W_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/W_trusteeMF_\"+str(24)+\".pth\"), requires_grad=True)\n",
    "nwi = np.load('drive/My Drive/IR_Project/npy_files/nwi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mwi = np.load('drive/My Drive/IR_Project/npy_files/mwi.npy')\n",
    "mbk = np.load('drive/My Drive/IR_Project/npy_files/mbk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "xKpAVf9eQvR9",
    "outputId": "4a420251-e6e0-4c67-ffc9-02c1efcaf7c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.08, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139986776931928, 139986743175712, 139988371950688]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.08, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139986776931928, 139986743175712, 139988371950688]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "alpha_lr = 0.08\n",
    "optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)\n",
    "checkpt = torch.load(\"drive/My Drive/IR_Project/optimizer_trusteeMF_24.pth\")\n",
    "optimizer.load_state_dict(checkpt)\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "xCDvur_yQvQG",
    "outputId": "648a0551-4435-43b4-f10f-b3b578be134e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  25 , loss:  tensor(34010.9922, grad_fn=<AddBackward0>) , time(seconds):  4018.45547246933\n",
      "Iteration:  26 , loss:  tensor(33434.8750, grad_fn=<AddBackward0>) , time(seconds):  4229.299179315567\n",
      "Iteration:  27 , loss:  tensor(32953.0547, grad_fn=<AddBackward0>) , time(seconds):  4185.780665874481\n",
      "Iteration:  28 , loss:  tensor(32059.2109, grad_fn=<AddBackward0>) , time(seconds):  4058.7082839012146\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(25, 25+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (5) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusteeMF, \"drive/My Drive/IR_Project/B_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusteeMF, \"drive/My Drive/IR_Project/V_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusteeMF, \"drive/My Drive/IR_Project/W_trusteeMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FQQ9JAfQvLU"
   },
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), \"drive/My Drive/IR_Project/optimizer_trusteeMF_28.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "wZNV9ebfxPEs",
    "outputId": "de143f49-13d8-460c-ca35-d2dbda7c667f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.08, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139986776931928, 139986743175712, 139988371950688]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139986776931928, 139986743175712, 139988371950688]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "alpha_lr = 0.1\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "3El9Q3soRjjs",
    "outputId": "cdfe08a3-036a-4c69-efe6-593dbe66b038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  29 , loss:  tensor(31730.7695, grad_fn=<AddBackward0>) , time(seconds):  3991.024946451187\n",
      "Iteration:  30 , loss:  tensor(31726.9453, grad_fn=<AddBackward0>) , time(seconds):  4250.053227901459\n",
      "Iteration:  31 , loss:  tensor(31635.4590, grad_fn=<AddBackward0>) , time(seconds):  4189.5547025203705\n",
      "Iteration:  32 , loss:  tensor(31092.6797, grad_fn=<AddBackward0>) , time(seconds):  4157.575653791428\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(29, 29+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (5) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusteeMF, \"drive/My Drive/IR_Project/B_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusteeMF, \"drive/My Drive/IR_Project/V_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusteeMF, \"drive/My Drive/IR_Project/W_trusteeMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RG75BAgQRja9"
   },
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), \"drive/My Drive/IR_Project/optimizer_trusteeMF_32.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kWfQ9GZcdy1j"
   },
   "outputs": [],
   "source": [
    "B_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/B_trusteeMF_\"+str(32)+\".pth\"), requires_grad=True)\n",
    "V_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/V_trusteeMF_\"+str(32)+\".pth\"), requires_grad=True)\n",
    "W_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/W_trusteeMF_\"+str(32)+\".pth\"), requires_grad=True)\n",
    "nwi = np.load('drive/My Drive/IR_Project/npy_files/nwi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mwi = np.load('drive/My Drive/IR_Project/npy_files/mwi.npy')\n",
    "mbk = np.load('drive/My Drive/IR_Project/npy_files/mbk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "0Vug_kMQaI80",
    "outputId": "04954fc5-55ed-4212-d41d-f1c3af6b6d33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140608972485472, 140610584456288, 140608972486048]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.2, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140608972485472, 140610584456288, 140608972486048]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "alpha_lr = 0.2\n",
    "optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)\n",
    "checkpt = torch.load(\"drive/My Drive/IR_Project/optimizer_trusteeMF_32.pth\")\n",
    "optimizer.load_state_dict(checkpt)\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aOG-BbqNYKCi",
    "outputId": "fd3ae35c-fcd5-48dc-8fb1-4a54de6f43f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  33 , loss:  tensor(30173.4531, grad_fn=<AddBackward0>) , time(seconds):  4130.186405181885\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(33, 33+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    loss.backward() # Loss corresponding to Eq. (5) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save(B_trusteeMF, \"drive/My Drive/IR_Project/B_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(V_trusteeMF, \"drive/My Drive/IR_Project/V_trusteeMF_\"+str(iteration)+\".pth\")\n",
    "    torch.save(W_trusteeMF, \"drive/My Drive/IR_Project/W_trusteeMF_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CuYXlhROYJ-w"
   },
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), \"drive/My Drive/IR_Project/optimizer_trusteeMF_34.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MNFLDNtCVMaq"
   },
   "source": [
    "### Predict Rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoIPVL7fGAye"
   },
   "outputs": [],
   "source": [
    "def get_model_parameters(iteration_r, iteration_e):\n",
    "    B_trusterMF = Variable(torch.load(\"drive/My Drive/IR_Project/B_trusterMF_\"+str(iteration_r)+\".pth\"), requires_grad=False)\n",
    "    V_trusterMF = Variable(torch.load(\"drive/My Drive/IR_Project/V_trusterMF_\"+str(iteration_r)+\".pth\"), requires_grad=False)\n",
    "    W_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/W_trusteeMF_\"+str(iteration_e)+\".pth\"), requires_grad=False)\n",
    "    V_trusteeMF = Variable(torch.load(\"drive/My Drive/IR_Project/V_trusteeMF_\"+str(iteration_e)+\".pth\"), requires_grad=False)\n",
    "    model_dict = {'B_trusterMF': B_trusterMF, 'V_trusterMF': V_trusterMF, 'W_trusteeMF': W_trusteeMF, 'V_trusteeMF': V_trusteeMF}\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l8M6sygAVPIK"
   },
   "outputs": [],
   "source": [
    "def predict_rating(model_dict, user_id, item_id):\n",
    "    global R_max \n",
    "    B_trusterMF = model_dict['B_trusterMF']\n",
    "    V_trusterMF = model_dict['V_trusterMF']\n",
    "    W_trusteeMF = model_dict['W_trusteeMF']\n",
    "    V_trusteeMF = model_dict['V_trusteeMF']\n",
    "    prediction = R_max * (torch.sigmoid((torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1]) + torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) / 2))\n",
    "    return prediction\n",
    "    # return prediction.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MB3nFwA6YTQc"
   },
   "source": [
    "### Validation on All Users (Paper Section 4.3.1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-A6zLm6YYSro"
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "def compute_MAE(model_dict, mode=\"train\"):\n",
    "    global ratings_data_train, ratings_data_test\n",
    "    if mode == \"train\":\n",
    "        data = ratings_data_train\n",
    "    else:\n",
    "        data = ratings_data_test\n",
    "    AE = torch.tensor(0.0)\n",
    "    for idx in range(len(data)):\n",
    "        user_id = int(data.iloc[idx][\"user_id\"])\n",
    "        item_id = int(data.iloc[idx][\"item_id\"])\n",
    "        rating = (data.iloc[idx][\"rating\"]) * R_max\n",
    "        AE += torch.abs(predict_rating(model_dict, user_id, item_id) - rating)\n",
    "    MAE = AE / len(data)\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbTV_RKFYXEm"
   },
   "outputs": [],
   "source": [
    "# Root Mean Square Error\n",
    "def compute_RMSE(model_dict, mode=\"train\"):\n",
    "    global ratings_data_train, ratings_data_test\n",
    "    if mode == \"train\":\n",
    "        data = ratings_data_train\n",
    "    else:\n",
    "        data = ratings_data_test\n",
    "    SE = torch.tensor(0.0)\n",
    "    for idx in range(len(data)):\n",
    "        user_id = int(data.iloc[idx][\"user_id\"])\n",
    "        item_id = int(data.iloc[idx][\"item_id\"])\n",
    "        rating = (data.iloc[idx][\"rating\"]) * R_max\n",
    "        SE += ((predict_rating(model_dict, user_id, item_id) - rating).pow(2))\n",
    "    MSE = SE / len(data)\n",
    "    RMSE = torch.sqrt(MSE)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNKblLE2YXBO"
   },
   "outputs": [],
   "source": [
    "model_dict = get_model_parameters(15, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jj3J8iV04azo",
    "outputId": "07a685ae-1aeb-4d79-c55a-c17ec4dc13ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5840)\n"
     ]
    }
   ],
   "source": [
    "print(compute_MAE(model_dict, mode=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Vpq4N9rw6OhK",
    "outputId": "a4c66e11-7d9b-4a62-82f9-f597020e1a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0989)\n"
     ]
    }
   ],
   "source": [
    "print(compute_MAE(model_dict, mode=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SLBU0e9f6m3U",
    "outputId": "0506d0ec-85a6-434a-f2b9-5ee59131b7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8359)\n"
     ]
    }
   ],
   "source": [
    "print(compute_RMSE(model_dict, mode=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4rJPa3qW6mz7",
    "outputId": "fcf240bd-e556-4907-da1c-283a53106910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4010)\n"
     ]
    }
   ],
   "source": [
    "print(compute_RMSE(model_dict, mode=\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SagiRfliXjF"
   },
   "source": [
    "### Validation on Cold Start Users (Paper Section 4.3.2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dxe7Xw6nJEyb"
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Error For Cold Start Users\n",
    "def compute_MAE_cold_start(model_dict, mode=\"train\", threshold=5):\n",
    "    global ratings_data_train, ratings_data_test\n",
    "    nbi = np.load('drive/My Drive/IR_Project/nbi.npy')\n",
    "    if mode == \"train\":\n",
    "        data = ratings_data_train\n",
    "    else:\n",
    "        data = ratings_data_test\n",
    "    AE = torch.tensor(0.0)\n",
    "    cnt = 0\n",
    "    for idx in range(len(data)):\n",
    "        user_id = int(data.iloc[idx][\"user_id\"])\n",
    "        if nbi[user_id-1] > threshold: # NOT A COLD START USER\n",
    "            continue\n",
    "        item_id = int(data.iloc[idx][\"item_id\"])\n",
    "        rating = (data.iloc[idx][\"rating\"]) * R_max\n",
    "        cnt += 1\n",
    "        AE += torch.abs(predict_rating(model_dict, user_id, item_id) - rating)\n",
    "    MAE = AE / cnt\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xvlA3xwRJEuw"
   },
   "outputs": [],
   "source": [
    "# Root Mean Square Error For Cold Start Users\n",
    "def compute_RMSE_cold_start(model_dict, mode=\"train\", threshold=5):\n",
    "    global ratings_data_train, ratings_data_test\n",
    "    nbi = np.load('drive/My Drive/IR_Project/nbi.npy')\n",
    "    if mode == \"train\":\n",
    "        data = ratings_data_train\n",
    "    else:\n",
    "        data = ratings_data_test\n",
    "    SE = torch.tensor(0.0)\n",
    "    cnt = 0\n",
    "    for idx in range(len(data)):\n",
    "        user_id = int(data.iloc[idx][\"user_id\"])\n",
    "        if nbi[user_id-1] > threshold: # NOT A COLD START USER\n",
    "            continue\n",
    "        item_id = int(data.iloc[idx][\"item_id\"])\n",
    "        rating = (data.iloc[idx][\"rating\"]) * R_max\n",
    "        cnt += 1\n",
    "        SE += ((predict_rating(model_dict, user_id, item_id) - rating).pow(2))\n",
    "    MSE = SE / cnt\n",
    "    RMSE = torch.sqrt(MSE)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZ4V38bK69lp"
   },
   "outputs": [],
   "source": [
    "model_dict = get_model_parameters(15, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vZjIHOAG-O-0",
    "outputId": "b6e08d75-2658-4792-fb1e-87e34e04acd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6509)\n"
     ]
    }
   ],
   "source": [
    "print(compute_MAE_cold_start(model_dict, mode=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CDEKyNip-O4T",
    "outputId": "009f0012-3f2a-491c-e15b-46aeee504750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2451)\n"
     ]
    }
   ],
   "source": [
    "print(compute_MAE_cold_start(model_dict, mode=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3c7jRYU5-O7r",
    "outputId": "d7f825b8-bd1e-4ca8-dad3-bd8a85e8911c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8196)\n"
     ]
    }
   ],
   "source": [
    "print(compute_RMSE_cold_start(model_dict, mode=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cKeqMNML-O0n",
    "outputId": "e07a745d-b7cc-4315-e022-35b187df1e3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4830)\n"
     ]
    }
   ],
   "source": [
    "print(compute_RMSE_cold_start(model_dict, mode=\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYo3CiUhN2cw"
   },
   "source": [
    "### Validation on Rank-Based Metrics (Paper Section 4.3.4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZ3IZTUkN1oQ"
   },
   "outputs": [],
   "source": [
    "def compute_omega():\n",
    "    global ratings_data_test, M\n",
    "    omega = []\n",
    "    for _ in range(M):\n",
    "        omega.append(set())\n",
    "    for idx in range(len(ratings_data_test)):\n",
    "        user_id = int(ratings_data_test.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_test.iloc[idx][\"item_id\"])\n",
    "        omega[user_id-1].add(item_id)\n",
    "    return omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-tN_RFCN_p5"
   },
   "outputs": [],
   "source": [
    "def compute_fav(threshold=4):\n",
    "    global ratings_data_test, M, R_max\n",
    "    fav = []\n",
    "    for _ in range(M):\n",
    "        fav.append(set())\n",
    "    for idx in range(len(ratings_data_test)):\n",
    "        user_id = int(ratings_data_test.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_test.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_test.iloc[idx][\"rating\"] * R_max\n",
    "        if rating >= threshold:\n",
    "            fav[user_id-1].add(item_id)\n",
    "    return fav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dt-KTT0hN_m1"
   },
   "outputs": [],
   "source": [
    "def compute_rec(model_dict, threshold=4):\n",
    "    global ratings_data_test, M\n",
    "    rec = []\n",
    "    for _ in range(M):\n",
    "        rec.append(set())\n",
    "    for idx in range(len(ratings_data_test)):\n",
    "        user_id = int(ratings_data_test.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_test.iloc[idx][\"item_id\"])\n",
    "        rating = predict_rating(model_dict, user_id, item_id)\n",
    "        if rating >= threshold:\n",
    "            rec[user_id-1].add(item_id)\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRpFzlbJR74O"
   },
   "outputs": [],
   "source": [
    "def compute_precision_recall_F1_score(rec, fav):\n",
    "    global M\n",
    "    precision = torch.tensor(0.0)\n",
    "    recall = torch.tensor(0.0)\n",
    "    for idx in range(M):\n",
    "        if len(rec[idx]) != 0:\n",
    "            precision += (len(rec[idx].intersection(fav[idx])) / len(rec[idx]))\n",
    "        if len(fav[idx]) != 0:\n",
    "            recall += (len(fav[idx].intersection(rec[idx])) / len(fav[idx]))\n",
    "    precision /= M\n",
    "    recall /= M\n",
    "    F1_score = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, F1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K7m38zxJ0s1x"
   },
   "source": [
    "### References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wks5wWH7Wzg"
   },
   "source": [
    "##### Epinions Dataset:\n",
    "http://www.trustlet.org/downloaded_epinions.html  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "O0ciwsrZ9kD4",
    "TeCx2ilBEZVt",
    "JlTXUdvDtxyV",
    "bSnSeuNM3hOe",
    "SQLLiRFf3ksm",
    "CYo3CiUhN2cw"
   ],
   "machine_shape": "hm",
   "name": "TrustMF_Model_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
