{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0ciwsrZ9kD4"
   },
   "source": [
    "### Import Packages & Define Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "ZoAMdVuEPuLs",
    "outputId": "b37b97f8-03dd-4ff7-f8ea-f4d42d908453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "POLcWrZZFWFS",
    "outputId": "e5a6a709-26d0-4d49-dbab-267c20fd79e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLZlxL-jEZVW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDWWpzlPEZVk"
   },
   "outputs": [],
   "source": [
    "R_max = 5 # Maximum rating value possible\n",
    "M = 49289  # No. of users in Epinions Dataset\n",
    "N = 139738  # No. of items in Epinions Dataset\n",
    "D = 10 # Dimensionality of latent space\n",
    "# Hyperparameters for loss function:\n",
    "lamda = 0.001\n",
    "beta1 = 10\n",
    "beta2 = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TeCx2ilBEZVt"
   },
   "source": [
    "### Read Data into Ratings Matrix and Trust Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjZX0IBLEZVv"
   },
   "outputs": [],
   "source": [
    "ratings_file = \"drive/My Drive/IR_Project/data/epinions_ratings_data.txt\"\n",
    "trust_file = \"drive/My Drive/IR_Project/data/standardized_epinions_trust_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5z2rly9n3ptZ"
   },
   "outputs": [],
   "source": [
    "def read_ratings_data():\n",
    "    global ratings_file\n",
    "    ratings_data = pd.read_csv(ratings_file, sep=\" \", header=None)\n",
    "    ratings_data.columns = [\"user_id\", \"item_id\", \"rating\"]\n",
    "    return ratings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cELMhC7l4uqo"
   },
   "outputs": [],
   "source": [
    "ratings_data = read_ratings_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "3eposBwb7byz",
    "outputId": "b6ad44a3-65f1-4165-e7a2-20595d874e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id      int64\n",
      "item_id      int64\n",
      "rating     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "ratings_data[\"rating\"] /= R_max\n",
    "convert_dict = {\"user_id\": int,\n",
    "                \"item_id\": int,\n",
    "                \"rating\": float}\n",
    "ratings_data = ratings_data.astype(convert_dict)\n",
    "print(ratings_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGAgFvS062E9"
   },
   "outputs": [],
   "source": [
    "def read_trust_data():\n",
    "    global trust_file\n",
    "    trust_data = pd.read_csv(trust_file, sep=\" \", header=None)\n",
    "    trust_data.columns = [\"user1_id\", \"user2_id\", \"trust_val\"]\n",
    "    return trust_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Sz1INY87tBO"
   },
   "outputs": [],
   "source": [
    "trust_data = read_trust_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hGRaVso7lNcm"
   },
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSwyEAPDjuBT"
   },
   "outputs": [],
   "source": [
    "ratings_data_train, ratings_data_test = train_test_split(ratings_data, train_size=TRAIN_RATIO, shuffle=True, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "X6PSgGpBlZ0y",
    "outputId": "dd47274a-67d2-4f47-98cb-b7461a66415f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531858\n",
      "132965\n"
     ]
    }
   ],
   "source": [
    "print(len(ratings_data_train))\n",
    "print(len(ratings_data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tbaZl-IuRY3B"
   },
   "source": [
    "### Train TrustPMF Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YKpW1kh8QSQg"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42) # Set any random seed for reproducibility\n",
    "# User feature matrix\n",
    "U_trustPMF = Variable(torch.empty((D, M)).normal_(mean=0.0, std=0.1), requires_grad=True)\n",
    "# Item feature matrix\n",
    "V_trustPMF = Variable(torch.empty((D, N)).normal_(mean=0.0, std=0.1), requires_grad=True)\n",
    "# Browse Reviews Behaviour Matrix (Influence from other users)\n",
    "B_trustPMF = Variable(torch.empty((D, M)).normal_(mean=0.0, std=0.1), requires_grad=True)\n",
    "# Write Reviews Behaviour Matrix (Influence other users)\n",
    "W_trustPMF = Variable(torch.empty((D, M)).normal_(mean=0.0, std=0.1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtQAUPNuR5bR"
   },
   "outputs": [],
   "source": [
    "# BORROWED FROM TRUSTMF MODEL TO AVOID RECOMPUTATION\n",
    "nui = np.load('drive/My Drive/IR_Project/npy_files/nbi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mbi = np.load('drive/My Drive/IR_Project/npy_files/mbi.npy')\n",
    "mwk = np.load('drive/My Drive/IR_Project/npy_files/mwk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbzREBFtTbh1"
   },
   "outputs": [],
   "source": [
    "epochs = 5 # No. of epochs\n",
    "alpha_lr = 0.4 # Learning Rate\n",
    "optimizer = optim.SGD([U_trustPMF, V_trustPMF, B_trustPMF, W_trustPMF], lr=alpha_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "83GZ4Y2KT6TD",
    "outputId": "306b6fe1-eeeb-4bdc-a80c-5e6619015b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 , loss:  tensor(198726.8594, grad_fn=<DivBackward0>) , time(seconds):  5561.856317520142\n",
      "Iteration:  1 , loss:  tensor(9301118., grad_fn=<DivBackward0>) , time(seconds):  6079.027758598328\n",
      "Iteration:  2 , loss:  tensor(1.0912e+09, grad_fn=<DivBackward0>) , time(seconds):  5980.297857999802\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(0, 0+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(U_trustPMF[:, user_id-1], V_trustPMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trustPMF[:, user1_id-1], W_trustPMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += (nui[user_id] * (U_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbi[user_id] * (B_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trustPMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trustPMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    beta1_loss = (U_trustPMF - B_trustPMF).pow(2).sum()\n",
    "    loss += (beta1 * beta1_loss)\n",
    "    beta2_loss = (U_trustPMF - W_trustPMF).pow(2).sum()\n",
    "    loss += (beta2 * beta2_loss)\n",
    "    loss /= 2\n",
    "    loss.backward() # Loss corresponding to Eq. (17) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save({'U_trustPMF': U_trustPMF,\n",
    "                'V_trustPMF': V_trustPMF,\n",
    "                'B_trustPMF': B_trustPMF,\n",
    "                'W_trustPMF': W_trustPMF,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'training_loss': loss,\n",
    "                'epoch': iteration\n",
    "    }, \"drive/My Drive/IR_Project/TrustPMF/checkpt_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDjkADffDeeP"
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "alpha_lr = 0.05\n",
    "optimizer = optim.SGD([U_trustPMF, V_trustPMF, B_trustPMF, W_trustPMF], lr=alpha_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "g8OTFpBRC2kA",
    "outputId": "62b117bc-247d-4e0d-d084-94527ecb716d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 , loss:  tensor(198726.8594, grad_fn=<DivBackward0>) , time(seconds):  5955.622653245926\n",
      "Iteration:  1 , loss:  tensor(124763.1016, grad_fn=<DivBackward0>) , time(seconds):  5976.91867852211\n",
      "Iteration:  2 , loss:  tensor(106230.1172, grad_fn=<DivBackward0>) , time(seconds):  6014.782845497131\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(0, 0+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(U_trustPMF[:, user_id-1], V_trustPMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trustPMF[:, user1_id-1], W_trustPMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += (nui[user_id] * (U_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbi[user_id] * (B_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trustPMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trustPMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    beta1_loss = (U_trustPMF - B_trustPMF).pow(2).sum()\n",
    "    loss += (beta1 * beta1_loss)\n",
    "    beta2_loss = (U_trustPMF - W_trustPMF).pow(2).sum()\n",
    "    loss += (beta2 * beta2_loss)\n",
    "    loss /= 2\n",
    "    loss.backward() # Loss corresponding to Eq. (17) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save({'U_trustPMF': U_trustPMF,\n",
    "                'V_trustPMF': V_trustPMF,\n",
    "                'B_trustPMF': B_trustPMF,\n",
    "                'W_trustPMF': W_trustPMF,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'training_loss': loss,\n",
    "                'epoch': iteration\n",
    "    }, \"drive/My Drive/IR_Project/TrustPMF/checkpt_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lup5EcN8FgzY"
   },
   "outputs": [],
   "source": [
    "nui = np.load('drive/My Drive/IR_Project/npy_files/nbi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mbi = np.load('drive/My Drive/IR_Project/npy_files/mbi.npy')\n",
    "mwk = np.load('drive/My Drive/IR_Project/npy_files/mwk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "wXsUkoLLC2fK",
    "outputId": "9d3df8ed-76f3-48ec-de05-d0cd0fa25d71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140185361624952, 140185361624088, 140185361622576, 140185361194944]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.025, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140185361624952, 140185361624088, 140185361622576, 140185361194944]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "alpha_lr = 0.025\n",
    "checkpoint = torch.load(\"drive/My Drive/IR_Project/TrustPMF/checkpt_\"+str(2)+\".pth\")\n",
    "U_trustPMF = Variable(checkpoint['U_trustPMF'], requires_grad=True)\n",
    "V_trustPMF = Variable(checkpoint['V_trustPMF'], requires_grad=True)\n",
    "B_trustPMF = Variable(checkpoint['B_trustPMF'], requires_grad=True)\n",
    "W_trustPMF = Variable(checkpoint['W_trustPMF'], requires_grad=True)\n",
    "optimizer = optim.SGD([U_trustPMF, V_trustPMF, B_trustPMF, W_trustPMF], lr=alpha_lr)\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "mN-4g5Shz0kb",
    "outputId": "b04c2c26-7a33-4f27-f5bd-75197ed52ef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3 , loss:  tensor(101563.2734, grad_fn=<DivBackward0>) , time(seconds):  5687.771916389465\n",
      "Iteration:  4 , loss:  tensor(100277.2891, grad_fn=<DivBackward0>) , time(seconds):  5991.082806825638\n",
      "Iteration:  5 , loss:  tensor(100090.0625, grad_fn=<DivBackward0>) , time(seconds):  5889.529284477234\n",
      "Iteration:  6 , loss:  tensor(99993.8047, grad_fn=<DivBackward0>) , time(seconds):  5696.646376609802\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(3, 3+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(U_trustPMF[:, user_id-1], V_trustPMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trustPMF[:, user1_id-1], W_trustPMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += (nui[user_id] * (U_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbi[user_id] * (B_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trustPMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trustPMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    beta1_loss = (U_trustPMF - B_trustPMF).pow(2).sum()\n",
    "    loss += (beta1 * beta1_loss)\n",
    "    beta2_loss = (U_trustPMF - W_trustPMF).pow(2).sum()\n",
    "    loss += (beta2 * beta2_loss)\n",
    "    loss /= 2\n",
    "    loss.backward() # Loss corresponding to Eq. (17) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save({'U_trustPMF': U_trustPMF,\n",
    "                'V_trustPMF': V_trustPMF,\n",
    "                'B_trustPMF': B_trustPMF,\n",
    "                'W_trustPMF': W_trustPMF,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'training_loss': loss,\n",
    "                'epoch': iteration\n",
    "    }, \"drive/My Drive/IR_Project/TrustPMF/checkpt_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "-ED3Jy8kFW_9",
    "outputId": "f0a5ea28-8bd7-4561-8333-70e56e705a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.075, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140185361624952, 140185361624088, 140185361622576, 140185361194944]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.075, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140185361624952, 140185361624088, 140185361622576, 140185361194944]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "alpha_lr = 0.075\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "v6oviscBFW6F",
    "outputId": "826d6802-3ffd-40cb-f9d5-fcd23be2745e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  7 , loss:  tensor(99893.7422, grad_fn=<DivBackward0>) , time(seconds):  6076.040097951889\n",
      "Iteration:  8 , loss:  tensor(99388.8203, grad_fn=<DivBackward0>) , time(seconds):  5759.2344534397125\n",
      "Iteration:  9 , loss:  tensor(97806.2031, grad_fn=<DivBackward0>) , time(seconds):  5562.523968458176\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(7, 7+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(U_trustPMF[:, user_id-1], V_trustPMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trustPMF[:, user1_id-1], W_trustPMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += (nui[user_id] * (U_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbi[user_id] * (B_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trustPMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trustPMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    beta1_loss = (U_trustPMF - B_trustPMF).pow(2).sum()\n",
    "    loss += (beta1 * beta1_loss)\n",
    "    beta2_loss = (U_trustPMF - W_trustPMF).pow(2).sum()\n",
    "    loss += (beta2 * beta2_loss)\n",
    "    loss /= 2\n",
    "    loss.backward() # Loss corresponding to Eq. (17) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save({'U_trustPMF': U_trustPMF,\n",
    "                'V_trustPMF': V_trustPMF,\n",
    "                'B_trustPMF': B_trustPMF,\n",
    "                'W_trustPMF': W_trustPMF,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'training_loss': loss,\n",
    "                'epoch': iteration\n",
    "    }, \"drive/My Drive/IR_Project/TrustPMF/checkpt_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKzoIHx-FWzd"
   },
   "outputs": [],
   "source": [
    "nui = np.load('drive/My Drive/IR_Project/npy_files/nbi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mbi = np.load('drive/My Drive/IR_Project/npy_files/mbi.npy')\n",
    "mwk = np.load('drive/My Drive/IR_Project/npy_files/mwk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "J913WhsJo10Q",
    "outputId": "01954322-86e8-4167-87b6-a7621a77d59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.075, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140405569741016, 140405569741448, 140405569742312, 140405569742384]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.04, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140405569741016, 140405569741448, 140405569742312, 140405569742384]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "alpha_lr = 0.04\n",
    "checkpoint = torch.load(\"drive/My Drive/IR_Project/TrustPMF/checkpt_\"+str(9)+\".pth\")\n",
    "U_trustPMF = Variable(checkpoint['U_trustPMF'], requires_grad=True)\n",
    "V_trustPMF = Variable(checkpoint['V_trustPMF'], requires_grad=True)\n",
    "B_trustPMF = Variable(checkpoint['B_trustPMF'], requires_grad=True)\n",
    "W_trustPMF = Variable(checkpoint['W_trustPMF'], requires_grad=True)\n",
    "optimizer = optim.SGD([U_trustPMF, V_trustPMF, B_trustPMF, W_trustPMF], lr=alpha_lr)\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "r3TNSeDJo1xE",
    "outputId": "2a2f1ffa-dec7-44e7-c169-b7b0c29a036c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  10 , loss:  tensor(93817.2500, grad_fn=<DivBackward0>) , time(seconds):  6054.57990527153\n",
      "Iteration:  11 , loss:  tensor(90621.4297, grad_fn=<DivBackward0>) , time(seconds):  6165.478798389435\n",
      "Iteration:  12 , loss:  tensor(87180.1562, grad_fn=<DivBackward0>) , time(seconds):  6064.954839229584\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10, 10+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(U_trustPMF[:, user_id-1], V_trustPMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trustPMF[:, user1_id-1], W_trustPMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += (nui[user_id] * (U_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbi[user_id] * (B_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trustPMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trustPMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    beta1_loss = (U_trustPMF - B_trustPMF).pow(2).sum()\n",
    "    loss += (beta1 * beta1_loss)\n",
    "    beta2_loss = (U_trustPMF - W_trustPMF).pow(2).sum()\n",
    "    loss += (beta2 * beta2_loss)\n",
    "    loss /= 2\n",
    "    loss.backward() # Loss corresponding to Eq. (17) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save({'U_trustPMF': U_trustPMF,\n",
    "                'V_trustPMF': V_trustPMF,\n",
    "                'B_trustPMF': B_trustPMF,\n",
    "                'W_trustPMF': W_trustPMF,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'training_loss': loss,\n",
    "                'epoch': iteration\n",
    "    }, \"drive/My Drive/IR_Project/TrustPMF/checkpt_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Lchpynmga2S"
   },
   "outputs": [],
   "source": [
    "nui = np.load('drive/My Drive/IR_Project/npy_files/nbi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mbi = np.load('drive/My Drive/IR_Project/npy_files/mbi.npy')\n",
    "mwk = np.load('drive/My Drive/IR_Project/npy_files/mwk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "J0uT5JzzPu1C",
    "outputId": "909210c0-c6c5-429c-94f7-75271dd2b9d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.04, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139906657109984, 139906657110056, 139906657110128, 139906657110632]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139906657109984, 139906657110056, 139906657110128, 139906657110632]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "alpha_lr = 0.1\n",
    "checkpoint = torch.load(\"drive/My Drive/IR_Project/TrustPMF/checkpt_\"+str(12)+\".pth\")\n",
    "U_trustPMF = Variable(checkpoint['U_trustPMF'], requires_grad=True)\n",
    "V_trustPMF = Variable(checkpoint['V_trustPMF'], requires_grad=True)\n",
    "B_trustPMF = Variable(checkpoint['B_trustPMF'], requires_grad=True)\n",
    "W_trustPMF = Variable(checkpoint['W_trustPMF'], requires_grad=True)\n",
    "optimizer = optim.SGD([U_trustPMF, V_trustPMF, B_trustPMF, W_trustPMF], lr=alpha_lr)\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "Atpm9sCOPuxU",
    "outputId": "5fa59fb6-6080-4ed2-a59e-99ec03e298f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  13 , loss:  tensor(83717.8906, grad_fn=<DivBackward0>) , time(seconds):  5659.433707952499\n",
      "Iteration:  14 , loss:  tensor(75569.0078, grad_fn=<DivBackward0>) , time(seconds):  5782.939474105835\n",
      "Iteration:  15 , loss:  tensor(68511.8047, grad_fn=<DivBackward0>) , time(seconds):  5924.827955007553\n",
      "Iteration:  16 , loss:  tensor(62486.7734, grad_fn=<DivBackward0>) , time(seconds):  5912.102276802063\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(13, 13+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(U_trustPMF[:, user_id-1], V_trustPMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trustPMF[:, user1_id-1], W_trustPMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += (nui[user_id] * (U_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbi[user_id] * (B_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trustPMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trustPMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    beta1_loss = (U_trustPMF - B_trustPMF).pow(2).sum()\n",
    "    loss += (beta1 * beta1_loss)\n",
    "    beta2_loss = (U_trustPMF - W_trustPMF).pow(2).sum()\n",
    "    loss += (beta2 * beta2_loss)\n",
    "    loss /= 2\n",
    "    loss.backward() # Loss corresponding to Eq. (17) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save({'U_trustPMF': U_trustPMF,\n",
    "                'V_trustPMF': V_trustPMF,\n",
    "                'B_trustPMF': B_trustPMF,\n",
    "                'W_trustPMF': W_trustPMF,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'training_loss': loss,\n",
    "                'epoch': iteration\n",
    "    }, \"drive/My Drive/IR_Project/TrustPMF/checkpt_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQUFaFCEgaxk"
   },
   "outputs": [],
   "source": [
    "nui = np.load('drive/My Drive/IR_Project/npy_files/nbi.npy')\n",
    "nvj = np.load('drive/My Drive/IR_Project/npy_files/nvj.npy')\n",
    "mbi = np.load('drive/My Drive/IR_Project/npy_files/mbi.npy')\n",
    "mwk = np.load('drive/My Drive/IR_Project/npy_files/mwk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "Q8H18HVfQJln",
    "outputId": "c422d775-233b-46b4-d4f8-7f45a6c245c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140148632909216, 140148632909648, 140148632910728, 140148632910800]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140148632909216, 140148632909648, 140148632910728, 140148632910800]}]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "alpha_lr = 0.1\n",
    "checkpoint = torch.load(\"drive/My Drive/IR_Project/TrustPMF/checkpt_\"+str(16)+\".pth\")\n",
    "U_trustPMF = Variable(checkpoint['U_trustPMF'], requires_grad=True)\n",
    "V_trustPMF = Variable(checkpoint['V_trustPMF'], requires_grad=True)\n",
    "B_trustPMF = Variable(checkpoint['B_trustPMF'], requires_grad=True)\n",
    "W_trustPMF = Variable(checkpoint['W_trustPMF'], requires_grad=True)\n",
    "optimizer = optim.SGD([U_trustPMF, V_trustPMF, B_trustPMF, W_trustPMF], lr=alpha_lr)\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "print(optimizer.state_dict())\n",
    "for pg in optimizer.param_groups:\n",
    "    pg['lr'] = alpha_lr\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "UWaIFDrGQJK4",
    "outputId": "182ce3a1-4eba-4038-e163-6c085ad985ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  17 , loss:  tensor(57613.6914, grad_fn=<DivBackward0>) , time(seconds):  6365.767110347748\n",
      "Iteration:  18 , loss:  tensor(54414.0234, grad_fn=<DivBackward0>) , time(seconds):  6334.696741819382\n",
      "Iteration:  19 , loss:  tensor(55510.2500, grad_fn=<DivBackward0>) , time(seconds):  5504.0817239284515\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(17, 17+epochs):\n",
    "    start = time.time()\n",
    "    loss = torch.tensor(0.0)\n",
    "    optimizer.zero_grad()\n",
    "    for idx in range(len(ratings_data_train)):\n",
    "        user_id = int(ratings_data_train.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_train.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_train.iloc[idx][\"rating\"]\n",
    "        loss += (torch.sigmoid(torch.dot(U_trustPMF[:, user_id-1], V_trustPMF[:, item_id-1])) - rating).pow(2)\n",
    "    for idx in range(len(trust_data)):\n",
    "        user1_id = trust_data.iloc[idx][\"user1_id\"]\n",
    "        user2_id = trust_data.iloc[idx][\"user2_id\"]\n",
    "        trust_val = trust_data.iloc[idx][\"trust_val\"]\n",
    "        loss += (torch.sigmoid(torch.dot(B_trustPMF[:, user1_id-1], W_trustPMF[:, user2_id-1])) - trust_val).pow(2)\n",
    "    reg_loss = torch.tensor(0.0)\n",
    "    for user_id in range(M):\n",
    "        reg_loss += (nui[user_id] * (U_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mbi[user_id] * (B_trustPMF[:, user_id].pow(2).sum()))\n",
    "        reg_loss += (mwk[user_id] * (W_trustPMF[:, user_id].pow(2).sum()))\n",
    "    for item_id in range(N):\n",
    "        reg_loss += (nvj[item_id] * (V_trustPMF[:, item_id].pow(2).sum()))\n",
    "    loss += (lamda * reg_loss)\n",
    "    beta1_loss = (U_trustPMF - B_trustPMF).pow(2).sum()\n",
    "    loss += (beta1 * beta1_loss)\n",
    "    beta2_loss = (U_trustPMF - W_trustPMF).pow(2).sum()\n",
    "    loss += (beta2 * beta2_loss)\n",
    "    loss /= 2\n",
    "    loss.backward() # Loss corresponding to Eq. (17) in the paper\n",
    "    optimizer.step()\n",
    "    end = time.time()\n",
    "    print(\"Iteration: \", iteration, \", loss: \", loss, \", time(seconds): \", end-start)\n",
    "    torch.save({'U_trustPMF': U_trustPMF,\n",
    "                'V_trustPMF': V_trustPMF,\n",
    "                'B_trustPMF': B_trustPMF,\n",
    "                'W_trustPMF': W_trustPMF,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'training_loss': loss,\n",
    "                'epoch': iteration\n",
    "    }, \"drive/My Drive/IR_Project/TrustPMF/checkpt_\"+str(iteration)+\".pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MNFLDNtCVMaq"
   },
   "source": [
    "### Predict Rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoIPVL7fGAye"
   },
   "outputs": [],
   "source": [
    "def get_model_parameters(iteration):\n",
    "    checkpoint = torch.load(\"drive/My Drive/IR_Project/TrustPMF/checkpt_\"+str(iteration)+\".pth\")\n",
    "    U_trustPMF = Variable(checkpoint['U_trustPMF'], requires_grad=False)\n",
    "    V_trustPMF = Variable(checkpoint['V_trustPMF'], requires_grad=False)\n",
    "    model_dict = {'U_trustPMF': U_trustPMF, 'V_trustPMF': V_trustPMF}\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l8M6sygAVPIK"
   },
   "outputs": [],
   "source": [
    "def predict_rating(model_dict, user_id, item_id):\n",
    "    global R_max \n",
    "    U_trustPMF = model_dict['U_trustPMF']\n",
    "    V_trustPMF = model_dict['V_trustPMF']\n",
    "    prediction = (1 + R_max) * torch.sigmoid(torch.dot(U_trustPMF[:, user_id-1], V_trustPMF[:, item_id-1]))\n",
    "    if prediction < 1:\n",
    "        return torch.tensor(1.0)\n",
    "    elif prediction > R_max:\n",
    "        return torch.tensor(R_max)\n",
    "    else:\n",
    "        return prediction\n",
    "        # return prediction.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MB3nFwA6YTQc"
   },
   "source": [
    "### Validation on All Users (Paper Section 4.3.1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-A6zLm6YYSro"
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "def compute_MAE(model_dict, mode=\"train\"):\n",
    "    global ratings_data_train, ratings_data_test\n",
    "    if mode == \"train\":\n",
    "        data = ratings_data_train\n",
    "    else:\n",
    "        data = ratings_data_test\n",
    "    AE = torch.tensor(0.0)\n",
    "    for idx in range(len(data)):\n",
    "        user_id = int(data.iloc[idx][\"user_id\"])\n",
    "        item_id = int(data.iloc[idx][\"item_id\"])\n",
    "        rating = (data.iloc[idx][\"rating\"]) * R_max\n",
    "        AE += torch.abs(predict_rating(model_dict, user_id, item_id) - rating)\n",
    "    MAE = AE / len(data)\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbTV_RKFYXEm"
   },
   "outputs": [],
   "source": [
    "# Root Mean Square Error\n",
    "def compute_RMSE(model_dict, mode=\"train\"):\n",
    "    global ratings_data_train, ratings_data_test\n",
    "    if mode == \"train\":\n",
    "        data = ratings_data_train\n",
    "    else:\n",
    "        data = ratings_data_test\n",
    "    SE = torch.tensor(0.0)\n",
    "    for idx in range(len(data)):\n",
    "        user_id = int(data.iloc[idx][\"user_id\"])\n",
    "        item_id = int(data.iloc[idx][\"item_id\"])\n",
    "        rating = (data.iloc[idx][\"rating\"]) * R_max\n",
    "        SE += ((predict_rating(model_dict, user_id, item_id) - rating).pow(2))\n",
    "    MSE = SE / len(data)\n",
    "    RMSE = torch.sqrt(MSE)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CynQQF0T6Nqg"
   },
   "outputs": [],
   "source": [
    "model_dict = get_model_parameters(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jj3J8iV04azo",
    "outputId": "03c04cfb-5b7d-4c83-df32-ff54d0c31e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1342)\n"
     ]
    }
   ],
   "source": [
    "print(compute_MAE(model_dict, mode=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Vpq4N9rw6OhK",
    "outputId": "71ea2f12-f1f5-4ad7-fec9-b1bbe77f7721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1993)\n"
     ]
    }
   ],
   "source": [
    "print(compute_MAE(model_dict, mode=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SLBU0e9f6m3U",
    "outputId": "45b17511-4fe4-4341-ba70-d75e1a8cf0e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3404)\n"
     ]
    }
   ],
   "source": [
    "print(compute_RMSE(model_dict, mode=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4rJPa3qW6mz7",
    "outputId": "887f16fb-a5ae-4f01-ce6e-6ce039bec3ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4065)\n"
     ]
    }
   ],
   "source": [
    "print(compute_RMSE(model_dict, mode=\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SagiRfliXjF"
   },
   "source": [
    "### Validation on Cold Start Users (Paper Section 4.3.2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dxe7Xw6nJEyb"
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Error For Cold Start Users\n",
    "def compute_MAE_cold_start(model_dict, mode=\"train\", threshold=5):\n",
    "    global ratings_data_train, ratings_data_test\n",
    "    nbi = np.load('drive/My Drive/IR_Project/nbi.npy')\n",
    "    if mode == \"train\":\n",
    "        data = ratings_data_train\n",
    "    else:\n",
    "        data = ratings_data_test\n",
    "    AE = torch.tensor(0.0)\n",
    "    cnt = 0\n",
    "    for idx in range(len(data)):\n",
    "        user_id = int(data.iloc[idx][\"user_id\"])\n",
    "        if nbi[user_id-1] > threshold: # NOT A COLD START USER\n",
    "            continue\n",
    "        item_id = int(data.iloc[idx][\"item_id\"])\n",
    "        rating = (data.iloc[idx][\"rating\"]) * R_max\n",
    "        cnt += 1\n",
    "        AE += torch.abs(predict_rating(model_dict, user_id, item_id) - rating)\n",
    "    MAE = AE / cnt\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xvlA3xwRJEuw"
   },
   "outputs": [],
   "source": [
    "# Root Mean Square Error For Cold Start Users\n",
    "def compute_RMSE_cold_start(model_dict, mode=\"train\", threshold=5):\n",
    "    global ratings_data_train, ratings_data_test\n",
    "    nbi = np.load('drive/My Drive/IR_Project/nbi.npy')\n",
    "    if mode == \"train\":\n",
    "        data = ratings_data_train\n",
    "    else:\n",
    "        data = ratings_data_test\n",
    "    SE = torch.tensor(0.0)\n",
    "    cnt = 0\n",
    "    for idx in range(len(data)):\n",
    "        user_id = int(data.iloc[idx][\"user_id\"])\n",
    "        if nbi[user_id-1] > threshold: # NOT A COLD START USER\n",
    "            continue\n",
    "        item_id = int(data.iloc[idx][\"item_id\"])\n",
    "        rating = (data.iloc[idx][\"rating\"]) * R_max\n",
    "        cnt += 1\n",
    "        SE += ((predict_rating(model_dict, user_id, item_id) - rating).pow(2))\n",
    "    MSE = SE / cnt\n",
    "    RMSE = torch.sqrt(MSE)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZ4V38bK69lp"
   },
   "outputs": [],
   "source": [
    "model_dict = get_model_parameters(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vZjIHOAG-O-0",
    "outputId": "636be97a-08d4-461e-c625-931d465bfd22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4317)\n"
     ]
    }
   ],
   "source": [
    "print(compute_MAE_cold_start(model_dict, mode=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CDEKyNip-O4T",
    "outputId": "64808833-33b6-4583-f1cd-7643a9232c2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4337)\n"
     ]
    }
   ],
   "source": [
    "print(compute_MAE_cold_start(model_dict, mode=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3c7jRYU5-O7r",
    "outputId": "06d88d94-dda9-48b6-a97c-6bc9d03794de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5639)\n"
     ]
    }
   ],
   "source": [
    "print(compute_RMSE_cold_start(model_dict, mode=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cKeqMNML-O0n",
    "outputId": "90f7d1d1-9b78-4cf3-cb50-cb592e06e4af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5720)\n"
     ]
    }
   ],
   "source": [
    "print(compute_RMSE_cold_start(model_dict, mode=\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYo3CiUhN2cw"
   },
   "source": [
    "### Validation on Rank-Based Metrics (Paper Section 4.3.4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZ3IZTUkN1oQ"
   },
   "outputs": [],
   "source": [
    "def compute_omega():\n",
    "    global ratings_data_test, M\n",
    "    omega = []\n",
    "    for _ in range(M):\n",
    "        omega.append(set())\n",
    "    for idx in range(len(ratings_data_test)):\n",
    "        user_id = int(ratings_data_test.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_test.iloc[idx][\"item_id\"])\n",
    "        omega[user_id-1].add(item_id)\n",
    "    return omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-tN_RFCN_p5"
   },
   "outputs": [],
   "source": [
    "def compute_fav(threshold=4):\n",
    "    global ratings_data_test, M, R_max\n",
    "    fav = []\n",
    "    for _ in range(M):\n",
    "        fav.append(set())\n",
    "    for idx in range(len(ratings_data_test)):\n",
    "        user_id = int(ratings_data_test.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_test.iloc[idx][\"item_id\"])\n",
    "        rating = ratings_data_test.iloc[idx][\"rating\"] * R_max\n",
    "        if rating >= threshold:\n",
    "            fav[user_id-1].add(item_id)\n",
    "    return fav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dt-KTT0hN_m1"
   },
   "outputs": [],
   "source": [
    "def compute_rec(model_dict, threshold=4):\n",
    "    global ratings_data_test, M\n",
    "    rec = []\n",
    "    for _ in range(M):\n",
    "        rec.append(set())\n",
    "    for idx in range(len(ratings_data_test)):\n",
    "        user_id = int(ratings_data_test.iloc[idx][\"user_id\"])\n",
    "        item_id = int(ratings_data_test.iloc[idx][\"item_id\"])\n",
    "        rating = predict_rating(model_dict, user_id, item_id)\n",
    "        if rating >= threshold:\n",
    "            rec[user_id-1].add(item_id)\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRpFzlbJR74O"
   },
   "outputs": [],
   "source": [
    "def compute_precision_recall_F1_score(rec, fav):\n",
    "    global M\n",
    "    precision = torch.tensor(0.0)\n",
    "    recall = torch.tensor(0.0)\n",
    "    for idx in range(M):\n",
    "        if len(rec[idx]) != 0:\n",
    "            precision += (len(rec[idx].intersection(fav[idx])) / len(rec[idx]))\n",
    "        if len(fav[idx]) != 0:\n",
    "            recall += (len(fav[idx].intersection(rec[idx])) / len(fav[idx]))\n",
    "    precision /= M\n",
    "    recall /= M\n",
    "    F1_score = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4I2mpyrR71H"
   },
   "outputs": [],
   "source": [
    "omega = compute_omega()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFVidA8Q_UVB"
   },
   "outputs": [],
   "source": [
    "fav = compute_fav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBoxf9er_hvU"
   },
   "outputs": [],
   "source": [
    "model_dict = get_model_parameters(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ZO2NRgh_UOH"
   },
   "outputs": [],
   "source": [
    "rec = compute_rec(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mQ-wfsQA_UKr",
    "outputId": "1db2dd10-b2f3-4fbc-850b-f75a666e2917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.0921), tensor(0.0431), tensor(0.0587))\n"
     ]
    }
   ],
   "source": [
    "print(compute_precision_recall_F1_score(rec, fav))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K7m38zxJ0s1x"
   },
   "source": [
    "### References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wks5wWH7Wzg"
   },
   "source": [
    "##### Epinions Dataset:\n",
    "http://www.trustlet.org/downloaded_epinions.html  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "O0ciwsrZ9kD4",
    "TeCx2ilBEZVt",
    "knVqMXbgqeWF"
   ],
   "name": "TrustPMF_Model_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
